{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "import cleantext\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", (tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reading datasets from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Curious to dive deeper', ' Happy', ' Neutral', ' Surprised',\n",
       "       ' Disgusted', ' Sad', ' Fearful', ' Angry'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topical_chat  = pd.read_csv('dataset/topical_chat.csv')\n",
    "topical_chat.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sentimental', 'afraid', 'proud', 'faithful', 'terrified',\n",
       "       'joyful', 'angry', 'sad', 'jealous', 'grateful', 'prepared',\n",
       "       'embarrassed', 'excited', 'annoyed', 'lonely', 'ashamed', 'guilty',\n",
       "       'surprised', 'nostalgic', 'confident', 'furious', 'disappointed',\n",
       "       'caring', 'trusting', 'disgusted', 'anticipating', 'anxious',\n",
       "       'hopeful', 'content', 'impressed', 'apprehensive', 'devastated',\n",
       "       ' I really killed it!', ' we were in a different country',\n",
       "       't even like scary things',\n",
       "       't believe I like the show Power so much. I was never really into shows like that',\n",
       "       nan, ' time to jump on the motorcycle and go cruising!',\n",
       "       \" a boy.  I hear all these different labor stories that aren't exactly reassuring!  \",\n",
       "       't believe my daughter taught herself how to play the ukelele. I was amazed',\n",
       "       't think I wold like super heroes',\n",
       "       \"m so mad with my brother. He stole from me and didn't think I would notice. \",\n",
       "       \" but what I didn't know was that he was working in the next room with the door open.  He approached and asked what I had been saying.  I knew I was caught.  I was so disgusted with myself.  \",\n",
       "       '('], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_emotion = pd.read_csv('dataset/emotion-emotion_69k.csv')\n",
    "emotion_emotion.emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Are you a fan of Google or Microsoft?</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Both are excellent technology they are helpfu...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm not  a huge fan of Google, but I use it a...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Google provides online related services and p...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yeah, their services are good. I'm just not a...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id                                            message  \\\n",
       "0                1              Are you a fan of Google or Microsoft?   \n",
       "1                1   Both are excellent technology they are helpfu...   \n",
       "2                1   I'm not  a huge fan of Google, but I use it a...   \n",
       "3                1   Google provides online related services and p...   \n",
       "4                1   Yeah, their services are good. I'm just not a...   \n",
       "\n",
       "                 sentiment  \n",
       "0   Curious to dive deeper  \n",
       "1   Curious to dive deeper  \n",
       "2   Curious to dive deeper  \n",
       "3   Curious to dive deeper  \n",
       "4   Curious to dive deeper  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topical_chat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Situation</th>\n",
       "      <th>emotion</th>\n",
       "      <th>empathetic_dialogues</th>\n",
       "      <th>labels</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>Customer :I remember going to see the firework...</td>\n",
       "      <td>Was this a friend you were in love with, or ju...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>Customer :This was a best friend. I miss her.\\...</td>\n",
       "      <td>Where has she gone?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>Customer :We no longer talk.\\nAgent :</td>\n",
       "      <td>Oh was this something that happened because of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>Customer :Was this a friend you were in love w...</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>Customer :Where has she gone?\\nAgent :</td>\n",
       "      <td>We no longer talk.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          Situation      emotion  \\\n",
       "0           0  I remember going to the fireworks with my best...  sentimental   \n",
       "1           1  I remember going to the fireworks with my best...  sentimental   \n",
       "2           2  I remember going to the fireworks with my best...  sentimental   \n",
       "3           3  I remember going to the fireworks with my best...  sentimental   \n",
       "4           4  I remember going to the fireworks with my best...  sentimental   \n",
       "\n",
       "                                empathetic_dialogues  \\\n",
       "0  Customer :I remember going to see the firework...   \n",
       "1  Customer :This was a best friend. I miss her.\\...   \n",
       "2              Customer :We no longer talk.\\nAgent :   \n",
       "3  Customer :Was this a friend you were in love w...   \n",
       "4             Customer :Where has she gone?\\nAgent :   \n",
       "\n",
       "                                              labels Unnamed: 5 Unnamed: 6  \n",
       "0  Was this a friend you were in love with, or ju...        NaN        NaN  \n",
       "1                                Where has she gone?        NaN        NaN  \n",
       "2  Oh was this something that happened because of...        NaN        NaN  \n",
       "3                This was a best friend. I miss her.        NaN        NaN  \n",
       "4                                 We no longer talk.        NaN        NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_emotion.head()\n",
    "# unique_emotions = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sentimental, caring,\n",
    "# afraid, terrified\n",
    "# proud, impressed\n",
    "# faithful, trusting, confident ,grateful,hopeful\n",
    "# joyful, happy\n",
    "# angry, furious\n",
    "# sad, devastated, disappointed, lonely\n",
    "# annoyed, ashamed, embarrassed, guilty\n",
    "# disgusted, jealous\n",
    "# anticipating, anxious, apprehensive,\n",
    "# neutral, content, prepared ,nostalgic\n",
    "# surprised, curious, excited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing and appending datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shrir\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py:5034: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "c:\\users\\shrir\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>sentimental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i used to scare for darkness</td>\n",
       "      <td>afraid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I showed a guy how to run a good bead in weldi...</td>\n",
       "      <td>proud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I have always been loyal to my wife.</td>\n",
       "      <td>faithful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A recent job interview that I had made me feel...</td>\n",
       "      <td>terrified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Line    Sentiment\n",
       "0   I remember going to the fireworks with my best...  sentimental\n",
       "5                        i used to scare for darkness       afraid\n",
       "10  I showed a guy how to run a good bead in weldi...        proud\n",
       "14               I have always been loyal to my wife.     faithful\n",
       "17  A recent job interview that I had made me feel...    terrified"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_subset = emotion_emotion[['Situation', 'emotion']]\n",
    "emotion_subset.rename(columns = {'Situation':'Line', 'emotion':'Sentiment'}, inplace = True)\n",
    "\n",
    "topical_subset = topical_chat[['message', 'sentiment']]\n",
    "topical_subset.rename(columns = {'message':'Line', 'sentiment':'Sentiment'}, inplace = True)\n",
    "\n",
    "emotion_subset.drop_duplicates(subset='Line', keep='first', inplace=True)\n",
    "emotion_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surprised                                                                                                                                                                                         3295\n",
       "excited                                                                                                                                                                                           2465\n",
       "angry                                                                                                                                                                                             2296\n",
       "proud                                                                                                                                                                                             2247\n",
       "annoyed                                                                                                                                                                                           2213\n",
       "sad                                                                                                                                                                                               2213\n",
       "lonely                                                                                                                                                                                            2106\n",
       "afraid                                                                                                                                                                                            2094\n",
       "grateful                                                                                                                                                                                          2091\n",
       "terrified                                                                                                                                                                                         2074\n",
       "guilty                                                                                                                                                                                            2053\n",
       "furious                                                                                                                                                                                           2045\n",
       "disgusted                                                                                                                                                                                         2044\n",
       "confident                                                                                                                                                                                         2037\n",
       "anxious                                                                                                                                                                                           2037\n",
       "anticipating                                                                                                                                                                                      2026\n",
       "hopeful                                                                                                                                                                                           2019\n",
       "impressed                                                                                                                                                                                         2004\n",
       "nostalgic                                                                                                                                                                                         1996\n",
       "disappointed                                                                                                                                                                                      1969\n",
       "jealous                                                                                                                                                                                           1955\n",
       "joyful                                                                                                                                                                                            1953\n",
       "prepared                                                                                                                                                                                          1937\n",
       "content                                                                                                                                                                                           1903\n",
       "devastated                                                                                                                                                                                        1856\n",
       "embarrassed                                                                                                                                                                                       1844\n",
       "sentimental                                                                                                                                                                                       1773\n",
       "caring                                                                                                                                                                                            1765\n",
       "trusting                                                                                                                                                                                          1755\n",
       "ashamed                                                                                                                                                                                           1694\n",
       "apprehensive                                                                                                                                                                                      1549\n",
       "faithful                                                                                                                                                                                          1283\n",
       "t even like scary things                                                                                                                                                                             5\n",
       "t believe my daughter taught herself how to play the ukelele. I was amazed                                                                                                                           5\n",
       " I really killed it!                                                                                                                                                                                 4\n",
       "t believe I like the show Power so much. I was never really into shows like that                                                                                                                     4\n",
       "t think I wold like super heroes                                                                                                                                                                     4\n",
       " but what I didn't know was that he was working in the next room with the door open.  He approached and asked what I had been saying.  I knew I was caught.  I was so disgusted with myself.         4\n",
       " we were in a different country                                                                                                                                                                      3\n",
       " time to jump on the motorcycle and go cruising!                                                                                                                                                     3\n",
       " a boy.  I hear all these different labor stories that aren't exactly reassuring!                                                                                                                    3\n",
       "m so mad with my brother. He stole from me and didn't think I would notice.                                                                                                                          3\n",
       "(                                                                                                                                                                                                    3\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_emotion.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Curious to dive deeper    80888\n",
       " Neutral                   41367\n",
       " Surprised                 30638\n",
       " Happy                     29617\n",
       " Sad                        2533\n",
       " Disgusted                  1433\n",
       " Fearful                    1026\n",
       " Angry                       876\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topical_chat.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188378, 2)\n"
     ]
    }
   ],
   "source": [
    "topical_subset.head()\n",
    "print(topical_subset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# rus  = RandomUnderSampler(random_state=69)\n",
    "# topical_subset_us, _ = rus.fit_resample(topical_subset, topical_subset['Sentiment'])\n",
    "# topical_subset_us = pd.DataFrame(topical_subset_us, columns=['Line','Sentiment'])\n",
    "#\n",
    "# topical_subset_us.reset_index(inplace = True, drop = True)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Totally agree. It's ridiculous that we don't ...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All they mentioned was that it was a truly he...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Right there is not one source out there that ...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think so that they can attempt to make them...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agreed! It's almost as ignorant as the judge ...</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Line Sentiment\n",
       "0   Totally agree. It's ridiculous that we don't ...     Angry\n",
       "1   All they mentioned was that it was a truly he...     Angry\n",
       "2   Right there is not one source out there that ...     Angry\n",
       "3   I think so that they can attempt to make them...     Angry\n",
       "4   Agreed! It's almost as ignorant as the judge ...     Angry"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topical_subset_us.head()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Angry                     876\n",
       " Curious to dive deeper    876\n",
       " Disgusted                 876\n",
       " Fearful                   876\n",
       " Happy                     876\n",
       " Neutral                   876\n",
       " Sad                       876\n",
       " Surprised                 876\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topical_subset_us.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207578</th>\n",
       "      <td>Wow, it does not seem like that long. Since I...</td>\n",
       "      <td>Surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207579</th>\n",
       "      <td>I havent seen that episode, I might google it...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207580</th>\n",
       "      <td>I don't think I have either. That's an insane...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207581</th>\n",
       "      <td>I did, my little brother used to love Thomas ...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207582</th>\n",
       "      <td>It did. Ringo Starr, George Carlin, and Alec ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Line  \\\n",
       "207578   Wow, it does not seem like that long. Since I...   \n",
       "207579   I havent seen that episode, I might google it...   \n",
       "207580   I don't think I have either. That's an insane...   \n",
       "207581   I did, my little brother used to love Thomas ...   \n",
       "207582   It did. Ringo Starr, George Carlin, and Alec ...   \n",
       "\n",
       "                      Sentiment  \n",
       "207578                Surprised  \n",
       "207579   Curious to dive deeper  \n",
       "207580   Curious to dive deeper  \n",
       "207581                    Happy  \n",
       "207582                  Neutral  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = emotion_subset\n",
    "# df_new = df_new.append(topical_subset_us, ignore_index=True)\n",
    "df_new = df_new.append(topical_subset, ignore_index=True)\n",
    "df_new.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentimental' 'afraid' 'proud' 'faithful' 'terrified' 'joyful' 'angry'\n",
      " 'sad' 'jealous' 'grateful' 'prepared' 'embarrassed' 'excited' 'annoyed'\n",
      " 'lonely' 'ashamed' 'guilty' 'surprised' 'nostalgic' 'confident' 'furious'\n",
      " 'disappointed' 'caring' 'trusting' 'disgusted' 'anticipating' 'anxious'\n",
      " 'hopeful' 'content' 'impressed' 'apprehensive' 'devastated'\n",
      " ' I really killed it!' ' we were in a different country'\n",
      " 't even like scary things'\n",
      " 't believe I like the show Power so much. I was never really into shows like that'\n",
      " nan ' time to jump on the motorcycle and go cruising!'\n",
      " \" a boy.  I hear all these different labor stories that aren't exactly reassuring!  \"\n",
      " 't think I wold like super heroes'\n",
      " \"m so mad with my brother. He stole from me and didn't think I would notice. \"\n",
      " \" but what I didn't know was that he was working in the next room with the door open.  He approached and asked what I had been saying.  I knew I was caught.  I was so disgusted with myself.  \"\n",
      " '(' ' Curious to dive deeper' ' Happy' ' Neutral' ' Surprised'\n",
      " ' Disgusted' ' Sad' ' Fearful' ' Angry']\n"
     ]
    }
   ],
   "source": [
    "print(df_new.Sentiment.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unique_sentiments = ['sentimental', 'afraid', 'proud', 'faithful', 'joyful', 'angry', 'sad', 'annoyed', 'disgusted', 'anticipating', 'neutral', 'surprised']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sentimental', 'afraid', 'proud', 'faithful', 'joyful', 'angry',\n",
       "       'sad', 'disgusted', 'neutral', 'annoyed', 'surprised',\n",
       "       'anticipating', ' I really killed it!',\n",
       "       ' we were in a different country', 't even like scary things',\n",
       "       't believe I like the show Power so much. I was never really into shows like that',\n",
       "       nan, ' time to jump on the motorcycle and go cruising!',\n",
       "       \" a boy.  I hear all these different labor stories that aren't exactly reassuring!  \",\n",
       "       't think I wold like super heroes',\n",
       "       \"m so mad with my brother. He stole from me and didn't think I would notice. \",\n",
       "       \" but what I didn't know was that he was working in the next room with the door open.  He approached and asked what I had been saying.  I knew I was caught.  I was so disgusted with myself.  \",\n",
       "       '('], dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(df_new)):\n",
    "    senti = str(df_new.Sentiment[i])\n",
    "    if senti == 'caring':\n",
    "        df_new.Sentiment[i] = 'sentimental'\n",
    "    elif senti == ' Happy':\n",
    "        df_new.Sentiment[i] = 'joyful'\n",
    "    elif senti == 'terrified' or senti == ' Fearful':\n",
    "        df_new.Sentiment[i] = 'afraid'\n",
    "    elif senti == 'impressed':\n",
    "        df_new.Sentiment[i] = 'proud'\n",
    "    elif senti == 'trusting' or senti == 'confident' or senti == 'grateful' or senti == 'hopeful':\n",
    "        df_new.Sentiment[i] = 'faithful'\n",
    "    elif senti == 'furious' or senti == ' Angry':\n",
    "        df_new.Sentiment[i] = 'angry'\n",
    "    elif senti == 'devastated' or senti == 'disappointed' or senti == 'lonely' or senti == ' Sad':\n",
    "        df_new.Sentiment[i] = 'sad'\n",
    "    elif senti == 'ashamed' or senti == 'embarrassed' or senti == 'guilty':\n",
    "        df_new.Sentiment[i] = 'annoyed'\n",
    "    if senti == 'jealous' or senti == ' Disgusted':\n",
    "        df_new.Sentiment[i] = 'disgusted'\n",
    "    elif senti == 'anxious' or senti == 'apprehensive':\n",
    "        df_new.Sentiment[i] = 'anticipating'\n",
    "    elif senti == 'content' or senti == 'prepared' or senti == 'nostalgic' or senti == ' Neutral':\n",
    "        df_new.Sentiment[i] = 'neutral'\n",
    "    elif senti == ' Curious to dive deeper' or senti == 'excited' or senti == ' Surprised':\n",
    "        df_new.Sentiment[i] = 'surprised'\n",
    "\n",
    "df_new.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sentimental', 'afraid', 'proud', 'faithful', 'joyful', 'angry',\n",
       "       'sad', 'disgusted', 'neutral', 'annoyed', 'surprised',\n",
       "       'anticipating'], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows from above list\n",
    "df_new = df_new[df_new.Sentiment.isin(unique_sentiments) == True]\n",
    "df_new.Sentiment.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_idx_dict = defaultdict()\n",
    "for i in range(len(unique_sentiments)):\n",
    "    sentiment_idx_dict[unique_sentiments[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "line  = list()\n",
    "sentiment_list = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>sentimental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i used to scare for darkness</td>\n",
       "      <td>afraid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I showed a guy how to run a good bead in weldi...</td>\n",
       "      <td>proud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have always been loyal to my wife.</td>\n",
       "      <td>faithful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A recent job interview that I had made me feel...</td>\n",
       "      <td>afraid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Line    Sentiment\n",
       "0  I remember going to the fireworks with my best...  sentimental\n",
       "1                       i used to scare for darkness       afraid\n",
       "2  I showed a guy how to run a good bead in weldi...        proud\n",
       "3               I have always been loyal to my wife.     faithful\n",
       "4  A recent job interview that I had made me feel...       afraid"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.reset_index(inplace = True, drop = True)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(df_new)):\n",
    "    # print(i)\n",
    "    line.append(str(df_new['Line'][i]).strip())\n",
    "    sentiment_list.append(sentiment_idx_dict[str(df_new['Sentiment'][i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415144 415144\n"
     ]
    }
   ],
   "source": [
    "print(len(line) , len(sentiment_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentimental', 'afraid', 'proud', 'faithful', 'joyful', 'angry', 'sad', 'annoyed', 'disgusted', 'anticipating', 'neutral', 'surprised']\n"
     ]
    }
   ],
   "source": [
    "print(unique_sentiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def contractions(s):\n",
    "    s = re.sub(r\"won't\", \"will not\", s)\n",
    "    s = re.sub(r\"wouldn't\", \"would not\",s)\n",
    "    s = re.sub(r\"couldn't\", \"could not\",s)\n",
    "    s = re.sub(r\"didn't\", \"did not\",s)\n",
    "    s = re.sub(r\"\\'d\", \" would\",s)\n",
    "    s = re.sub(r\"can\\'t\", \"can not\",s)\n",
    "    s = re.sub(r\"n\\'t\", \" not\", s)\n",
    "    s = re.sub(r\"\\'re\", \" are\", s)\n",
    "    s = re.sub(r\"\\'s\", \" is\", s)\n",
    "    s = re.sub(r\"\\'ll\", \" will\", s)\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    s = re.sub(r\"\\'ve\", \" have\", s)\n",
    "    s = re.sub(r\"\\'m\", \" am\", s)\n",
    "    return s\n",
    "# data[‘pre_process']=data[‘pre_process'].apply(lambda x:contractions(x))\n",
    "\n",
    "def lemmatize(ip):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_lines = []\n",
    "    for line in ip:\n",
    "        new_line = ''\n",
    "        tokens = nltk.word_tokenize(line)\n",
    "        for t in tokens:\n",
    "            t = contractions(t)\n",
    "            lemmatizer.lemmatize(t)\n",
    "            new_line += t + ' '\n",
    "        new_line.strip()\n",
    "        lemmatized_lines.append(new_line)\n",
    "    return lemmatized_lines\n",
    "\n",
    "\n",
    "def clean(ip):\n",
    "    clean_lines = list()\n",
    "    for i , sentences in enumerate(ip):\n",
    "        # print(ip[i])\n",
    "        clean_line = (cleantext.clean(str(ip[i]), extra_spaces=True, lowercase=True, stopwords=True, stemming=False, numbers=True, punct=True, clean_all = True))\n",
    "        clean_lines.append(clean_line)\n",
    "    return clean_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Line  Emotion\n",
      "0  I remember going to the fireworks with my best...        0\n",
      "1                       i used to scare for darkness        1\n",
      "2  I showed a guy how to run a good bead in weldi...        2\n",
      "3               I have always been loyal to my wife.        3\n",
      "4  A recent job interview that I had made me feel...        1\n"
     ]
    }
   ],
   "source": [
    "df_sentiment = pd.DataFrame(list(zip(line, sentiment_list)), columns=['Line', 'Emotion'])\n",
    "print(df_sentiment.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_sentiment['Line'] = df_sentiment['Line'].apply(lambda x: ' '.join(x.lower() for x in str(x).split()))\n",
    "df_sentiment['Line'] = df_sentiment['Line'].apply(lambda x: contractions(x))\n",
    "df_sentiment['Line'] = df_sentiment['Line'].apply(lambda x: ' '.join([re.sub('[^A-Za-z]+','', x) for x in nltk.word_tokenize(x)]))\n",
    "df_sentiment['Line'] = df_sentiment['Line'].apply(lambda x: re.sub(' +', ' ', x))\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "df_sentiment['Line'] = df_sentiment['Line'].apply(lambda x: ' '.join([x for x in x.split() if x not in stop]))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df_sentiment['Line'] = df_sentiment['Line'].apply(lambda x: ' '.join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(x)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>remember going firework best friend lot people...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>used scare darkness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>showed guy run good bead welding class caught ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>always loyal wife</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recent job interview made feel anxious felt li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Line  Emotion\n",
       "0  remember going firework best friend lot people...        0\n",
       "1                                used scare darkness        1\n",
       "2  showed guy run good bead welding class caught ...        2\n",
       "3                                  always loyal wife        3\n",
       "4  recent job interview made feel anxious felt li...        1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 415144 entries, 0 to 415143\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   Line     415144 non-null  object\n",
      " 1   Emotion  415144 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sentiment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_sentiment = df_sentiment[df_sentiment['Line'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    226500\n",
       "10     86228\n",
       "4      60426\n",
       "6       9940\n",
       "3       5460\n",
       "8       5246\n",
       "7       4620\n",
       "1       4514\n",
       "5       4290\n",
       "9       3334\n",
       "2       2554\n",
       "0       2032\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_sentiment.to_csv('dataset/line_sentiment.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reading saved dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>remember going firework best friend lot people...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>used scare darkness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>showed guy run good bead welding class caught ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>always loyal wife</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recent job interview made feel anxious felt li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Line  Emotion\n",
       "0  remember going firework best friend lot people...        0\n",
       "1                                used scare darkness        1\n",
       "2  showed guy run good bead welding class caught ...        2\n",
       "3                                  always loyal wife        3\n",
       "4  recent job interview made feel anxious felt li...        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment = pd.read_csv('dataset/line_sentiment.csv')\n",
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Vectorizing inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (372301,) (372301,) Test:  ((41367,), (41367,))\n"
     ]
    }
   ],
   "source": [
    "df_sentiment = df_sentiment[df_sentiment['Line'].notna()]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_sentiment['Line'], df_sentiment['Emotion'], random_state=42, train_size=0.9)\n",
    "print('Train: ',X_train.shape,Y_train.shape,'Test: ',(X_test.shape,Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129991    hey know netflix make percent internet bandwid...\n",
      "161547                            say human side effect hum\n",
      "204452    saw president indonesia released three pop alb...\n",
      "128660    like idea crime fighting duo using subway woul...\n",
      "238782    lol right kind miss though like going store pi...\n",
      "                                ...                        \n",
      "260051    really know almost hobbit character name taken...\n",
      "367121    yeah feed addiction clicking fb mostly blue zu...\n",
      "132382                            yes use play nintendo kid\n",
      "147366                  surprised lasted long display color\n",
      "122376                         sued million even make sense\n",
      "Name: Line, Length: 372301, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Vectorizer……\n"
     ]
    }
   ],
   "source": [
    "print('TFIDF Vectorizer……')\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_x_train = vectorizer.fit_transform(X_train)\n",
    "tf_x_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 34695)\t0.49169857843455916\n",
      "  (0, 32466)\t0.245651782509468\n",
      "  (0, 25138)\t0.3908650135451507\n",
      "  (0, 21715)\t0.14645538503268263\n",
      "  (0, 19648)\t0.39128059852921226\n",
      "  (0, 17997)\t0.4635974844806341\n",
      "  (0, 17786)\t0.24855348760564516\n",
      "  (0, 17572)\t0.250867727159096\n",
      "  (0, 10453)\t0.17585927318052288\n",
      "  (1, 30222)\t0.32170127940111987\n",
      "  (1, 26564)\t0.28814353759393396\n",
      "  (1, 23387)\t0.20337748770115177\n",
      "  (1, 20364)\t0.2093034795564782\n",
      "  (1, 20177)\t0.18878858684785316\n",
      "  (1, 16576)\t0.24080541572755182\n",
      "  (1, 15261)\t0.5593425626936508\n",
      "  (1, 13197)\t0.3788415706724859\n",
      "  (1, 8078)\t0.38147123294352775\n",
      "  (1, 995)\t0.18104563257635967\n",
      "  (2, 35003)\t0.2715127362499651\n",
      "  (2, 29453)\t0.4502987125082147\n",
      "  (2, 24084)\t0.3533564370968893\n",
      "  (2, 23685)\t0.4765782329115876\n",
      "  (2, 15492)\t0.5117043769274519\n",
      "  (2, 13451)\t0.3311841639901435\n",
      "  :\t:\n",
      "  (41364, 17143)\t0.1919310720564133\n",
      "  (41364, 13061)\t0.3036236351772873\n",
      "  (41364, 5122)\t0.32619299075530306\n",
      "  (41364, 1469)\t0.4132284796458545\n",
      "  (41365, 34781)\t0.14437420152375438\n",
      "  (41365, 33646)\t0.37125885099905703\n",
      "  (41365, 31331)\t0.2852719609191055\n",
      "  (41365, 31325)\t0.14693547835670479\n",
      "  (41365, 31316)\t0.19894643005385573\n",
      "  (41365, 30583)\t0.3897424577540697\n",
      "  (41365, 28851)\t0.22126818355661926\n",
      "  (41365, 27231)\t0.3155347670129572\n",
      "  (41365, 17143)\t0.12581967522793594\n",
      "  (41365, 14834)\t0.2508648323871718\n",
      "  (41365, 12598)\t0.3590138183242096\n",
      "  (41365, 11376)\t0.34761501887058316\n",
      "  (41365, 6775)\t0.1886432986213361\n",
      "  (41365, 995)\t0.18513506782076572\n",
      "  (41366, 34781)\t0.24084858850897672\n",
      "  (41366, 34175)\t0.2939531435676793\n",
      "  (41366, 32154)\t0.46897274646653375\n",
      "  (41366, 30348)\t0.42319225602591465\n",
      "  (41366, 20856)\t0.32127385197460867\n",
      "  (41366, 5122)\t0.3567240627110964\n",
      "  (41366, 990)\t0.4754865291798842\n"
     ]
    }
   ],
   "source": [
    "print(tf_x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Logistic Regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_ll = LogisticRegression(max_iter=1000,solver='liblinear')\n",
    "lr_ll.fit(tf_x_train,Y_train)\n",
    "y_test_pred = lr_ll.predict(tf_x_test)\n",
    "report_lr_ll = classification_report(Y_test, y_test_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'f1-score': 0.39024390243902435,\n",
      "       'precision': 0.5773195876288659,\n",
      "       'recall': 0.29473684210526313,\n",
      "       'support': 190},\n",
      " '1': {'f1-score': 0.4654654654654655,\n",
      "       'precision': 0.7635467980295566,\n",
      "       'recall': 0.3347732181425486,\n",
      "       'support': 463},\n",
      " '10': {'f1-score': 0.3760454002389486,\n",
      "        'precision': 0.5370014928556195,\n",
      "        'recall': 0.28932551993565436,\n",
      "        'support': 8703},\n",
      " '11': {'f1-score': 0.7545730605162316,\n",
      "        'precision': 0.6361586053457682,\n",
      "        'recall': 0.9271532003731178,\n",
      "        'support': 22513},\n",
      " '2': {'f1-score': 0.48793565683646123,\n",
      "       'precision': 0.7777777777777778,\n",
      "       'recall': 0.35546875,\n",
      "       'support': 256},\n",
      " '3': {'f1-score': 0.5324074074074074,\n",
      "       'precision': 0.6515580736543909,\n",
      "       'recall': 0.4500978473581213,\n",
      "       'support': 511},\n",
      " '4': {'f1-score': 0.22484439834024894,\n",
      "       'precision': 0.5139300533491404,\n",
      "       'recall': 0.14390041493775935,\n",
      "       'support': 6025},\n",
      " '5': {'f1-score': 0.38289962825278817,\n",
      "       'precision': 0.7686567164179104,\n",
      "       'recall': 0.25495049504950495,\n",
      "       'support': 404},\n",
      " '6': {'f1-score': 0.43297587131367293,\n",
      "       'precision': 0.6320939334637965,\n",
      "       'recall': 0.3292558613659531,\n",
      "       'support': 981},\n",
      " '7': {'f1-score': 0.6549707602339182,\n",
      "       'precision': 0.7161125319693095,\n",
      "       'recall': 0.603448275862069,\n",
      "       'support': 464},\n",
      " '8': {'f1-score': 0.35259259259259257,\n",
      "       'precision': 0.7484276729559748,\n",
      "       'recall': 0.23062015503875968,\n",
      "       'support': 516},\n",
      " '9': {'f1-score': 0.5179856115107914,\n",
      "       'precision': 0.6697674418604651,\n",
      "       'recall': 0.4222873900293255,\n",
      "       'support': 341},\n",
      " 'accuracy': 0.6226944182560978,\n",
      " 'macro avg': {'f1-score': 0.46441164626229586,\n",
      "               'precision': 0.6660292237757147,\n",
      "               'recall': 0.38633483084983977,\n",
      "               'support': 41367},\n",
      " 'weighted avg': {'f1-score': 0.5691411167987784,\n",
      "                  'precision': 0.6034892178717398,\n",
      "                  'recall': 0.6226944182560978,\n",
      "                  'support': 41367}}\n",
      "0.6226944182560978\n"
     ]
    }
   ],
   "source": [
    "pprint(report_lr_ll)\n",
    "print(report_lr_ll['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### newton-cg solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_ncg = LogisticRegression(max_iter=1000,solver='newton-cg')\n",
    "lr_ncg.fit(tf_x_train,Y_train)\n",
    "y_test_pred = lr_ncg.predict(tf_x_test)\n",
    "report_lr_ncg = classification_report(Y_test, y_test_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'f1-score': 0.42675159235668786,\n",
      "       'precision': 0.5403225806451613,\n",
      "       'recall': 0.3526315789473684,\n",
      "       'support': 190},\n",
      " '1': {'f1-score': 0.5102639296187683,\n",
      "       'precision': 0.7945205479452054,\n",
      "       'recall': 0.3758099352051836,\n",
      "       'support': 463},\n",
      " '10': {'f1-score': 0.400262754543464,\n",
      "        'precision': 0.5486194477791116,\n",
      "        'recall': 0.31506377111340916,\n",
      "        'support': 8703},\n",
      " '11': {'f1-score': 0.7580277757366449,\n",
      "        'precision': 0.6463051718196912,\n",
      "        'recall': 0.9164482743303869,\n",
      "        'support': 22513},\n",
      " '2': {'f1-score': 0.5333333333333333,\n",
      "       'precision': 0.7248322147651006,\n",
      "       'recall': 0.421875,\n",
      "       'support': 256},\n",
      " '3': {'f1-score': 0.5555555555555556,\n",
      "       'precision': 0.611764705882353,\n",
      "       'recall': 0.5088062622309197,\n",
      "       'support': 511},\n",
      " '4': {'f1-score': 0.2528358961431813,\n",
      "       'precision': 0.5254059717129387,\n",
      "       'recall': 0.16647302904564315,\n",
      "       'support': 6025},\n",
      " '5': {'f1-score': 0.4028520499108735,\n",
      "       'precision': 0.7197452229299363,\n",
      "       'recall': 0.27970297029702973,\n",
      "       'support': 404},\n",
      " '6': {'f1-score': 0.4481648422408242,\n",
      "       'precision': 0.6083916083916084,\n",
      "       'recall': 0.3547400611620795,\n",
      "       'support': 981},\n",
      " '7': {'f1-score': 0.679203539823009,\n",
      "       'precision': 0.6977272727272728,\n",
      "       'recall': 0.6616379310344828,\n",
      "       'support': 464},\n",
      " '8': {'f1-score': 0.4032921810699588,\n",
      "       'precision': 0.6901408450704225,\n",
      "       'recall': 0.28488372093023256,\n",
      "       'support': 516},\n",
      " '9': {'f1-score': 0.5354058721934369,\n",
      "       'precision': 0.6512605042016807,\n",
      "       'recall': 0.45454545454545453,\n",
      "       'support': 341},\n",
      " 'accuracy': 0.6298740541977905,\n",
      " 'macro avg': {'f1-score': 0.49216244354381145,\n",
      "               'precision': 0.6465863411558735,\n",
      "               'recall': 0.4243848324035158,\n",
      "               'support': 41367},\n",
      " 'weighted avg': {'f1-score': 0.5830319847977176,\n",
      "                  'precision': 0.6103588532624111,\n",
      "                  'recall': 0.6298740541977905,\n",
      "                  'support': 41367}}\n",
      "0.6298740541977905\n"
     ]
    }
   ],
   "source": [
    "pprint(report_lr_ncg)\n",
    "print(report_lr_ncg['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### lbfgs solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_lbfgs = LogisticRegression(max_iter=1000,solver='lbfgs')\n",
    "lr_lbfgs.fit(tf_x_train,Y_train)\n",
    "y_test_pred = lr_lbfgs.predict(tf_x_test)\n",
    "report_lr_lbfgs = classification_report(Y_test, y_test_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'f1-score': 0.42675159235668786,\n",
      "       'precision': 0.5403225806451613,\n",
      "       'recall': 0.3526315789473684,\n",
      "       'support': 190},\n",
      " '1': {'f1-score': 0.5102639296187683,\n",
      "       'precision': 0.7945205479452054,\n",
      "       'recall': 0.3758099352051836,\n",
      "       'support': 463},\n",
      " '10': {'f1-score': 0.4003796451777762,\n",
      "        'precision': 0.5490588706447738,\n",
      "        'recall': 0.31506377111340916,\n",
      "        'support': 8703},\n",
      " '11': {'f1-score': 0.7580505905909584,\n",
      "        'precision': 0.6463162510963538,\n",
      "        'recall': 0.9164926931106472,\n",
      "        'support': 22513},\n",
      " '2': {'f1-score': 0.5333333333333333,\n",
      "       'precision': 0.7248322147651006,\n",
      "       'recall': 0.421875,\n",
      "       'support': 256},\n",
      " '3': {'f1-score': 0.5555555555555556,\n",
      "       'precision': 0.611764705882353,\n",
      "       'recall': 0.5088062622309197,\n",
      "       'support': 511},\n",
      " '4': {'f1-score': 0.2528040327662256,\n",
      "       'precision': 0.525130890052356,\n",
      "       'recall': 0.16647302904564315,\n",
      "       'support': 6025},\n",
      " '5': {'f1-score': 0.4028520499108735,\n",
      "       'precision': 0.7197452229299363,\n",
      "       'recall': 0.27970297029702973,\n",
      "       'support': 404},\n",
      " '6': {'f1-score': 0.4481648422408242,\n",
      "       'precision': 0.6083916083916084,\n",
      "       'recall': 0.3547400611620795,\n",
      "       'support': 981},\n",
      " '7': {'f1-score': 0.679203539823009,\n",
      "       'precision': 0.6977272727272728,\n",
      "       'recall': 0.6616379310344828,\n",
      "       'support': 464},\n",
      " '8': {'f1-score': 0.4032921810699588,\n",
      "       'precision': 0.6901408450704225,\n",
      "       'recall': 0.28488372093023256,\n",
      "       'support': 516},\n",
      " '9': {'f1-score': 0.540447504302926,\n",
      "       'precision': 0.6541666666666667,\n",
      "       'recall': 0.4604105571847507,\n",
      "       'support': 341},\n",
      " 'accuracy': 0.6299465757729591,\n",
      " 'macro avg': {'f1-score': 0.49259156639557466,\n",
      "               'precision': 0.6468431397347675,\n",
      "               'recall': 0.4248772925218122,\n",
      "               'support': 41367},\n",
      " 'weighted avg': {'f1-score': 0.583105912075711,\n",
      "                  'precision': 0.6104412222848422,\n",
      "                  'recall': 0.6299465757729591,\n",
      "                  'support': 41367}}\n",
      "0.6299465757729591\n"
     ]
    }
   ],
   "source": [
    "pprint(report_lr_lbfgs)\n",
    "print(report_lr_lbfgs['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### sag solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_sag = LogisticRegression(max_iter=1000,solver='sag')\n",
    "lr_sag.fit(tf_x_train,Y_train)\n",
    "y_test_pred = lr_sag.predict(tf_x_test)\n",
    "report_lr_sag = classification_report(Y_test, y_test_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'f1-score': 0.42675159235668786,\n",
      "       'precision': 0.5403225806451613,\n",
      "       'recall': 0.3526315789473684,\n",
      "       'support': 190},\n",
      " '1': {'f1-score': 0.5102639296187683,\n",
      "       'precision': 0.7945205479452054,\n",
      "       'recall': 0.3758099352051836,\n",
      "       'support': 463},\n",
      " '10': {'f1-score': 0.4002919708029198,\n",
      "        'precision': 0.5487292375425256,\n",
      "        'recall': 0.31506377111340916,\n",
      "        'support': 8703},\n",
      " '11': {'f1-score': 0.7580505905909584,\n",
      "        'precision': 0.6463162510963538,\n",
      "        'recall': 0.9164926931106472,\n",
      "        'support': 22513},\n",
      " '2': {'f1-score': 0.5333333333333333,\n",
      "       'precision': 0.7248322147651006,\n",
      "       'recall': 0.421875,\n",
      "       'support': 256},\n",
      " '3': {'f1-score': 0.5555555555555556,\n",
      "       'precision': 0.611764705882353,\n",
      "       'recall': 0.5088062622309197,\n",
      "       'support': 511},\n",
      " '4': {'f1-score': 0.2528358961431813,\n",
      "       'precision': 0.5254059717129387,\n",
      "       'recall': 0.16647302904564315,\n",
      "       'support': 6025},\n",
      " '5': {'f1-score': 0.4028520499108735,\n",
      "       'precision': 0.7197452229299363,\n",
      "       'recall': 0.27970297029702973,\n",
      "       'support': 404},\n",
      " '6': {'f1-score': 0.4481648422408242,\n",
      "       'precision': 0.6083916083916084,\n",
      "       'recall': 0.3547400611620795,\n",
      "       'support': 981},\n",
      " '7': {'f1-score': 0.679203539823009,\n",
      "       'precision': 0.6977272727272728,\n",
      "       'recall': 0.6616379310344828,\n",
      "       'support': 464},\n",
      " '8': {'f1-score': 0.4032921810699588,\n",
      "       'precision': 0.6901408450704225,\n",
      "       'recall': 0.28488372093023256,\n",
      "       'support': 516},\n",
      " '9': {'f1-score': 0.5354058721934369,\n",
      "       'precision': 0.6512605042016807,\n",
      "       'recall': 0.45454545454545453,\n",
      "       'support': 341},\n",
      " 'accuracy': 0.62989822805618,\n",
      " 'macro avg': {'f1-score': 0.4921667794699589,\n",
      "               'precision': 0.6465964135758799,\n",
      "               'recall': 0.42438853396853754,\n",
      "               'support': 41367},\n",
      " 'weighted avg': {'f1-score': 0.5830505479016701,\n",
      "                  'precision': 0.6103879810228601,\n",
      "                  'recall': 0.62989822805618,\n",
      "                  'support': 41367}}\n",
      "0.62989822805618\n"
     ]
    }
   ],
   "source": [
    "pprint(report_lr_sag)\n",
    "print(report_lr_sag['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### saga solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_saga = LogisticRegression(max_iter=1000,solver='saga')\n",
    "lr_saga.fit(tf_x_train,Y_train)\n",
    "y_test_pred = lr_saga.predict(tf_x_test)\n",
    "report_lr_saga = classification_report(Y_test, y_test_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'f1-score': 0.42675159235668786,\n",
      "       'precision': 0.5403225806451613,\n",
      "       'recall': 0.3526315789473684,\n",
      "       'support': 190},\n",
      " '1': {'f1-score': 0.5102639296187683,\n",
      "       'precision': 0.7945205479452054,\n",
      "       'recall': 0.3758099352051836,\n",
      "       'support': 463},\n",
      " '10': {'f1-score': 0.40032119132783417,\n",
      "        'precision': 0.5488390712570056,\n",
      "        'recall': 0.31506377111340916,\n",
      "        'support': 8703},\n",
      " '11': {'f1-score': 0.7580277757366449,\n",
      "        'precision': 0.6463051718196912,\n",
      "        'recall': 0.9164482743303869,\n",
      "        'support': 22513},\n",
      " '2': {'f1-score': 0.5333333333333333,\n",
      "       'precision': 0.7248322147651006,\n",
      "       'recall': 0.421875,\n",
      "       'support': 256},\n",
      " '3': {'f1-score': 0.5555555555555556,\n",
      "       'precision': 0.611764705882353,\n",
      "       'recall': 0.5088062622309197,\n",
      "       'support': 511},\n",
      " '4': {'f1-score': 0.2528358961431813,\n",
      "       'precision': 0.5254059717129387,\n",
      "       'recall': 0.16647302904564315,\n",
      "       'support': 6025},\n",
      " '5': {'f1-score': 0.4028520499108735,\n",
      "       'precision': 0.7197452229299363,\n",
      "       'recall': 0.27970297029702973,\n",
      "       'support': 404},\n",
      " '6': {'f1-score': 0.4481648422408242,\n",
      "       'precision': 0.6083916083916084,\n",
      "       'recall': 0.3547400611620795,\n",
      "       'support': 981},\n",
      " '7': {'f1-score': 0.679203539823009,\n",
      "       'precision': 0.6977272727272728,\n",
      "       'recall': 0.6616379310344828,\n",
      "       'support': 464},\n",
      " '8': {'f1-score': 0.4032921810699588,\n",
      "       'precision': 0.6901408450704225,\n",
      "       'recall': 0.28488372093023256,\n",
      "       'support': 516},\n",
      " '9': {'f1-score': 0.540447504302926,\n",
      "       'precision': 0.6541666666666667,\n",
      "       'recall': 0.4604105571847507,\n",
      "       'support': 341},\n",
      " 'accuracy': 0.6299224019145696,\n",
      " 'macro avg': {'f1-score': 0.4925874492849664,\n",
      "               'precision': 0.6468468233177801,\n",
      "               'recall': 0.4248735909567905,\n",
      "               'support': 41367},\n",
      " 'weighted avg': {'f1-score': 0.5830858386397586,\n",
      "                  'precision': 0.6104290150949992,\n",
      "                  'recall': 0.6299224019145696,\n",
      "                  'support': 41367}}\n",
      "0.6299224019145696\n"
     ]
    }
   ],
   "source": [
    "pprint(report_lr_saga)\n",
    "print(report_lr_saga['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### saving logistic regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'lr_ll.sav'\n",
    "pickle.dump(lr_ll, open(f'models/{filename}', 'wb'))\n",
    "\n",
    "filename = 'lr_ncg.sav'\n",
    "pickle.dump(lr_ncg, open(f'models/{filename}', 'wb'))\n",
    "\n",
    "filename = 'lr_lbfgs.sav'\n",
    "pickle.dump(lr_lbfgs, open(f'models/{filename}', 'wb'))\n",
    "\n",
    "filename = 'lr_sag.sav'\n",
    "pickle.dump(lr_sag, open(f'models/{filename}', 'wb'))\n",
    "\n",
    "filename = 'lr_saga.sav'\n",
    "pickle.dump(lr_saga, open(f'models/{filename}', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading saved linear regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'lr_ll.sav'\n",
    "lr_ll = pickle.load(open(f'models/{filename}', 'rb'))\n",
    "\n",
    "filename = 'lr_ncg.sav'\n",
    "lr_ncg = pickle.load(open(f'models/{filename}', 'rb'))\n",
    "\n",
    "filename = 'lr_lbfgs.sav'\n",
    "lr_lbfgs = pickle.load(open(f'models/{filename}', 'rb'))\n",
    "\n",
    "filename = 'lr_sag.sav'\n",
    "lr_sag = pickle.load(open(f'models/{filename}', 'rb'))\n",
    "\n",
    "filename = 'lr_saga.sav'\n",
    "lr_saga = pickle.load(open(f'models/{filename}', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "svm = LinearSVC(random_state=0)\n",
    "svm.fit(tf_x_train,Y_train)\n",
    "y_test_pred = svm.predict(tf_x_test)\n",
    "report_svm = classification_report(Y_test, y_test_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'f1-score': 0.6301369863013698,\n",
      "       'precision': 0.6571428571428571,\n",
      "       'recall': 0.6052631578947368,\n",
      "       'support': 190},\n",
      " '1': {'f1-score': 0.6287978863936593,\n",
      "       'precision': 0.8095238095238095,\n",
      "       'recall': 0.5140388768898488,\n",
      "       'support': 463},\n",
      " '10': {'f1-score': 0.4352872896111434,\n",
      "        'precision': 0.5904349537492619,\n",
      "        'recall': 0.3447087211306446,\n",
      "        'support': 8703},\n",
      " '11': {'f1-score': 0.7736338028169013,\n",
      "        'precision': 0.670136968474477,\n",
      "        'recall': 0.9149380358015369,\n",
      "        'support': 22513},\n",
      " '2': {'f1-score': 0.7004219409282699,\n",
      "       'precision': 0.7614678899082569,\n",
      "       'recall': 0.6484375,\n",
      "       'support': 256},\n",
      " '3': {'f1-score': 0.6872509960159363,\n",
      "       'precision': 0.6997971602434077,\n",
      "       'recall': 0.675146771037182,\n",
      "       'support': 511},\n",
      " '4': {'f1-score': 0.33949739212897106,\n",
      "       'precision': 0.593944421401908,\n",
      "       'recall': 0.23767634854771785,\n",
      "       'support': 6025},\n",
      " '5': {'f1-score': 0.5965996908809892,\n",
      "       'precision': 0.7942386831275721,\n",
      "       'recall': 0.4777227722772277,\n",
      "       'support': 404},\n",
      " '6': {'f1-score': 0.5397412199630314,\n",
      "       'precision': 0.6822429906542056,\n",
      "       'recall': 0.44648318042813456,\n",
      "       'support': 981},\n",
      " '7': {'f1-score': 0.7698833510074232,\n",
      "       'precision': 0.7578288100208769,\n",
      "       'recall': 0.7823275862068966,\n",
      "       'support': 464},\n",
      " '8': {'f1-score': 0.5784919653893695,\n",
      "       'precision': 0.7986348122866894,\n",
      "       'recall': 0.45348837209302323,\n",
      "       'support': 516},\n",
      " '9': {'f1-score': 0.6884735202492213,\n",
      "       'precision': 0.7342192691029901,\n",
      "       'recall': 0.6480938416422287,\n",
      "       'support': 341},\n",
      " 'accuracy': 0.6609858099451253,\n",
      " 'macro avg': {'f1-score': 0.6140180034738572,\n",
      "               'precision': 0.7124677188030261,\n",
      "               'recall': 0.5623604303290982,\n",
      "               'support': 41367},\n",
      " 'weighted avg': {'f1-score': 0.6249657264929058,\n",
      "                  'precision': 0.6493173933722252,\n",
      "                  'recall': 0.6609858099451253,\n",
      "                  'support': 41367}}\n",
      "0.6609858099451253\n"
     ]
    }
   ],
   "source": [
    "pprint(report_svm)\n",
    "print(report_svm['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### saving svm models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'svm.sav'\n",
    "pickle.dump(lr_ll, open(f'models/{filename}', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Loading saved svm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'svm.sav'\n",
    "svm = pickle.load(open(f'models/{filename}', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SGD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(tf_x_train, Y_train)\n",
    "y_test_pred = sgd.predict(tf_x_test)\n",
    "report_sgd = classification_report(Y_test, y_test_pred,output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'f1-score': 0.3296703296703297,\n",
      "       'precision': 0.5421686746987951,\n",
      "       'recall': 0.23684210526315788,\n",
      "       'support': 190},\n",
      " '1': {'f1-score': 0.35725677830940994,\n",
      "       'precision': 0.6829268292682927,\n",
      "       'recall': 0.24190064794816415,\n",
      "       'support': 463},\n",
      " '10': {'f1-score': 0.11409604812778756,\n",
      "        'precision': 0.5863539445628998,\n",
      "        'recall': 0.06319659887395151,\n",
      "        'support': 8703},\n",
      " '11': {'f1-score': 0.732438545226421,\n",
      "        'precision': 0.5828428796636889,\n",
      "        'recall': 0.985341802514103,\n",
      "        'support': 22513},\n",
      " '2': {'f1-score': 0.3856041131105399,\n",
      "       'precision': 0.5639097744360902,\n",
      "       'recall': 0.29296875,\n",
      "       'support': 256},\n",
      " '3': {'f1-score': 0.42821158690176325,\n",
      "       'precision': 0.6007067137809188,\n",
      "       'recall': 0.33268101761252444,\n",
      "       'support': 511},\n",
      " '4': {'f1-score': 0.09627282329862684,\n",
      "       'precision': 0.5299003322259136,\n",
      "       'recall': 0.05294605809128631,\n",
      "       'support': 6025},\n",
      " '5': {'f1-score': 0.30739299610894943,\n",
      "       'precision': 0.7181818181818181,\n",
      "       'recall': 0.19554455445544555,\n",
      "       'support': 404},\n",
      " '6': {'f1-score': 0.314176245210728,\n",
      "       'precision': 0.6327160493827161,\n",
      "       'recall': 0.2089704383282365,\n",
      "       'support': 981},\n",
      " '7': {'f1-score': 0.5374233128834356,\n",
      "       'precision': 0.6239316239316239,\n",
      "       'recall': 0.47198275862068967,\n",
      "       'support': 464},\n",
      " '8': {'f1-score': 0.2702702702702703,\n",
      "       'precision': 0.7522123893805309,\n",
      "       'recall': 0.16472868217054262,\n",
      "       'support': 516},\n",
      " '9': {'f1-score': 0.4424131627056673,\n",
      "       'precision': 0.587378640776699,\n",
      "       'recall': 0.3548387096774194,\n",
      "       'support': 341},\n",
      " 'accuracy': 0.5841129402663959,\n",
      " 'macro avg': {'f1-score': 0.3596021843186607,\n",
      "               'precision': 0.6169358058574989,\n",
      "               'recall': 0.3001618436296267,\n",
      "               'support': 41367},\n",
      " 'weighted avg': {'f1-score': 0.47332581750840635,\n",
      "                  'precision': 0.582022885781462,\n",
      "                  'recall': 0.5841129402663959,\n",
      "                  'support': 41367}}\n",
      "0.5841129402663959\n"
     ]
    }
   ],
   "source": [
    "pprint(report_sgd)\n",
    "print(report_sgd['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### saving sgd models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'sgd.sav'\n",
    "pickle.dump(lr_ll, open(f'models/{filename}', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Loading saved svm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'sgd.sav'\n",
    "sgd = pickle.load(open(f'models/{filename}', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2 ... 11  4 10]\n"
     ]
    }
   ],
   "source": [
    "df_sentiment = df_sentiment[df_sentiment['Line'].notna()]\n",
    "y = df_sentiment.iloc[:, 1].values\n",
    "y = np.array([int(i) for i in y])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples Training data : 372301\n",
      "No. of samples Validation data : 41367\n"
     ]
    }
   ],
   "source": [
    "# split data into training and validation set in ratio of 9:1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_sentiment['Line'], y, random_state=42, train_size=0.9, stratify=y)\n",
    "\n",
    "print('No. of samples Training data :', X_train.shape[0])\n",
    "print('No. of samples Validation data :', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_dataset/'+\"sentiment_classifer\" +'.pickle','wb') as f:\n",
    "        pickle.dump([X_train],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF on text data ... \n"
     ]
    }
   ],
   "source": [
    "print (\"TF-IDF on text data ... \")\n",
    "tfidf = TfidfVectorizer(binary=True)\n",
    "X_train = tfidf.fit_transform(X_train).astype('float16')\n",
    "X_test = tfidf.transform(X_test).astype('float16')\n",
    "# print(f'train_text[0]: {X_train[0]}')\n",
    "# print(f'X[0]: {X[0]}')\n",
    "# print(f'X shape: {X.shape}')\n",
    "\n",
    "ip_dim = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"tfdf.pickle\", \"wb+\")\n",
    "pickle.dump(tfidf, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "num_classes = np.max(Y_train) + 1\n",
    "Y_train_onehot = to_categorical(Y_train, num_classes=num_classes)\n",
    "Y_test_onehot = to_categorical(Y_test, num_classes=num_classes)\n",
    "print(num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model ... \n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "print (\"Create model ... \")\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=ip_dim, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(160, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(120, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(80, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.Precision()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compile model ...\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2909/2909 [==============================] - 45s 14ms/step - loss: 1.1510 - accuracy: 0.5781 - precision: 0.6767 - val_loss: 1.0040 - val_accuracy: 0.6236 - val_precision: 0.7140\n",
      "Epoch 2/15\n",
      "2909/2909 [==============================] - 42s 14ms/step - loss: 0.9066 - accuracy: 0.6735 - precision: 0.7440 - val_loss: 0.8384 - val_accuracy: 0.6971 - val_precision: 0.7704\n",
      "Epoch 3/15\n",
      "2909/2909 [==============================] - 43s 15ms/step - loss: 0.6930 - accuracy: 0.7571 - precision: 0.8110 - val_loss: 0.7194 - val_accuracy: 0.7456 - val_precision: 0.7909\n",
      "Epoch 4/15\n",
      "2909/2909 [==============================] - 46s 16ms/step - loss: 0.5539 - accuracy: 0.8079 - precision: 0.8524 - val_loss: 0.6145 - val_accuracy: 0.7874 - val_precision: 0.8328\n",
      "Epoch 5/15\n",
      "2909/2909 [==============================] - 45s 15ms/step - loss: 0.4663 - accuracy: 0.8395 - precision: 0.8763 - val_loss: 0.5528 - val_accuracy: 0.8147 - val_precision: 0.8555\n",
      "Epoch 6/15\n",
      "2909/2909 [==============================] - 46s 15ms/step - loss: 0.4071 - accuracy: 0.8593 - precision: 0.8914 - val_loss: 0.5132 - val_accuracy: 0.8323 - val_precision: 0.8672\n",
      "Epoch 7/15\n",
      "2909/2909 [==============================] - 48s 16ms/step - loss: 0.3620 - accuracy: 0.8756 - precision: 0.9038 - val_loss: 0.4798 - val_accuracy: 0.8474 - val_precision: 0.8749\n",
      "Epoch 8/15\n",
      "2909/2909 [==============================] - 47s 16ms/step - loss: 0.3281 - accuracy: 0.8876 - precision: 0.9132 - val_loss: 0.4509 - val_accuracy: 0.8623 - val_precision: 0.8876\n",
      "Epoch 9/15\n",
      "2909/2909 [==============================] - 47s 16ms/step - loss: 0.3021 - accuracy: 0.8963 - precision: 0.9199 - val_loss: 0.4264 - val_accuracy: 0.8699 - val_precision: 0.8978\n",
      "Epoch 10/15\n",
      "2909/2909 [==============================] - 45s 15ms/step - loss: 0.2790 - accuracy: 0.9040 - precision: 0.9262 - val_loss: 0.4220 - val_accuracy: 0.8785 - val_precision: 0.9032\n",
      "Epoch 11/15\n",
      "2909/2909 [==============================] - 46s 15ms/step - loss: 0.2618 - accuracy: 0.9098 - precision: 0.9306 - val_loss: 0.4251 - val_accuracy: 0.8814 - val_precision: 0.9037\n",
      "Epoch 12/15\n",
      "2909/2909 [==============================] - 43s 15ms/step - loss: 0.2456 - accuracy: 0.9151 - precision: 0.9354 - val_loss: 0.3956 - val_accuracy: 0.8890 - val_precision: 0.9114\n",
      "Epoch 13/15\n",
      "2909/2909 [==============================] - 46s 16ms/step - loss: 0.2324 - accuracy: 0.9200 - precision: 0.9382 - val_loss: 0.4021 - val_accuracy: 0.8936 - val_precision: 0.9156\n",
      "Epoch 14/15\n",
      "2909/2909 [==============================] - 48s 16ms/step - loss: 0.2209 - accuracy: 0.9242 - precision: 0.9416 - val_loss: 0.4074 - val_accuracy: 0.8938 - val_precision: 0.9117\n",
      "Epoch 15/15\n",
      "2909/2909 [==============================] - 47s 16ms/step - loss: 0.2096 - accuracy: 0.9277 - precision: 0.9444 - val_loss: 0.3935 - val_accuracy: 0.8989 - val_precision: 0.9193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26b01b7fd00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Compile model ...\")\n",
    "model_dnn = build_model()\n",
    "model_dnn.fit(X_train, Y_train_onehot, epochs=15, batch_size=128, validation_data=(X_test, Y_test_onehot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Saving dnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'model_dnn.h5'\n",
    "model_dnn.save(f'models/{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading saved dnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'model_dnn.h5'\n",
    "model_dnn = load_model(f'models/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tfgpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "04ee3065d2333376d0aa8ad1893b6f4d1e1600d75ce606d1ee7a0507ce07e97f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
